'use client'

import { useState } from 'react'

export default function Home() {
  const [input, setInput] = useState('')
  const [reply, setReply] = useState('')
  const [listening, setListening] = useState(false)
  const [recording, setRecording] = useState(false) // âœ… éŒ²éŸ³ç”¨

  const handleSubmit = async () => {
    const res = await fetch('/api/ai', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ prompt: input }),
    })
    const data = await res.json()
    const answer = data.result || 'è¿”ä¿¡ãªã—'
    setReply(answer)

    // éŸ³å£°å‡ºåŠ›
    const utterance = new SpeechSynthesisUtterance(answer)
    utterance.lang = 'ja-JP'
    speechSynthesis.speak(utterance)
  }

  // ğŸ¤ Whisperç”¨ éŸ³å£°éŒ²éŸ³ã—ã¦ /api/whisper ã«é€ä¿¡
  const handleSTT = async () => {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
    const mediaRecorder = new MediaRecorder(stream)
    const chunks: Blob[] = []

    mediaRecorder.ondataavailable = (e) => {
      chunks.push(e.data)
    }

    mediaRecorder.onstop = async () => {
      const blob = new Blob(chunks, { type: 'audio/webm' })
      const res = await fetch('/api/whisper', {
        method: 'POST',
        body: blob,
      })
      const data = await res.json()
      setInput(data.text || '') // Whisperçµæœã‚’å…¥åŠ›æ¬„ã«
      setRecording(false)
    }

    mediaRecorder.start()
    setRecording(true)
    setTimeout(() => mediaRecorder.stop(), 5000) // â± éŒ²éŸ³æ™‚é–“
  }

  const startListening = () => {
    if (!('webkitSpeechRecognition' in window)) {
      alert('éŸ³å£°èªè­˜ã¯ã“ã®ãƒ–ãƒ©ã‚¦ã‚¶ã§ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚')
      return
    }

    const recognition = new (window as any).webkitSpeechRecognition()
    recognition.lang = 'ja-JP'
    recognition.interimResults = false
    recognition.continuous = false

    recognition.onstart = () => {
      setListening(true)
    }

    recognition.onresult = (event: Event) => {
      const result = (event as any).results?.[0]?.[0]?.transcript
      if (result) setInput(result)
      setListening(false)
    }

    recognition.onerror = (event: any) => {
      console.error('èªè­˜ã‚¨ãƒ©ãƒ¼', event.error)
      setListening(false)
    }

    recognition.onend = () => {
      setListening(false)
    }

    recognition.start()
  }

  return (
    <main className="min-h-screen flex flex-col items-center justify-center bg-gray-100 p-4">
      <h1 className="text-3xl font-bold mb-4">AIãƒ­ãƒ¼ãƒ—ãƒ¬ï¼ˆéŸ³å£°å¯¾å¿œï¼‰</h1>
      <textarea
        value={input}
        onChange={(e) => setInput(e.target.value)}
        className="w-full max-w-md h-32 p-2 border rounded mb-2"
        placeholder="è©±ã™ã‹ã€å…¥åŠ›ã—ã¦ãã ã•ã„"
      />
      <div className="flex space-x-2 mb-4">
        <button
          onClick={startListening}
          className={`px-4 py-2 rounded text-white ${listening ? 'bg-red-500' : 'bg-green-500'} hover:opacity-80`}
        >
          {listening ? 'éŒ²éŸ³ä¸­...' : 'ğŸ¤ è©±ã™'}
        </button>
        <button
          onClick={handleSTT}
          className={`px-4 py-2 rounded text-white ${recording ? 'bg-red-600' : 'bg-purple-600'} hover:opacity-80`}
        >
          {recording ? 'éŒ²éŸ³ä¸­...' : 'ğŸ¤ éŸ³å£°ã§è³ªå•'}
        </button>
        <button
          onClick={handleSubmit}
          className="bg-blue-500 text-white px-4 py-2 rounded hover:bg-blue-600"
        >
          é€ä¿¡
        </button>
      </div>
      <div className="mt-4 p-2 bg-white border rounded max-w-md w-full min-h-[50px]">
        {reply}
      </div>
    </main>
  )
}
